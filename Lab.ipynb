{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cce977-ee7a-49f4-a79c-48884adc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "numerical = pd.read_csv('./files_for_lab/numerical.csv')\n",
    "categorical = pd.read_csv('./files_for_lab/categorical.csv')\n",
    "targets = pd.read_csv('./files_for_lab/target.csv')\n",
    "data = pd.concat([numerical, categorical, targets], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e3ba63-7120-42a6-9dba-560658d0d644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90569, 339)\n",
      "(181138, 339)\n"
     ]
    }
   ],
   "source": [
    "category_1 = data[data['TARGET_B']==1].sample(len(data[data['TARGET_B']==0]), replace=True)\n",
    "print(category_1.shape)\n",
    "\n",
    "category_0 = data[data['TARGET_B'] == 0 ]\n",
    "data = pd.concat([category_0, category_1], axis = 0)\n",
    "data = data.dropna()\n",
    "data = data.sample(frac =1) #randomize the rows\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46a0816-94db-4fcc-b9e4-cb8e2e77fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "numericalX = X.select_dtypes(np.number)\n",
    "categoricalX = X.select_dtypes(np.object)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first').fit(categoricalX)\n",
    "encoded_categorical = encoder.transform(categoricalX).toarray()\n",
    "encoded_categorical = pd.DataFrame(encoded_categorical)\n",
    "X = pd.concat([numericalX, encoded_categorical], axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa55c4eb-8f24-4405-b583-4bc2a3909d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train_regression = X_train['TARGET_D']\n",
    "y_test_regression = X_test['TARGET_D']\n",
    "\n",
    "X_train = X_train.drop(['TARGET_D'], axis = 1)\n",
    "X_test = X_test.drop(['TARGET_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe40c4e-5dba-40f7-ac52-8b930042a990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616106548892416\n",
      "0.614497074086342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0b38a8-2c91-4c03-8b02-8a54366f8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Runs for too long...\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=5,\n",
    "#                              min_samples_split=20,\n",
    "#                              min_samples_leaf =20)\n",
    "# cross_val_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "# print(np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da5fc57-a734-452a-8304-22634721c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11150,  7028],\n",
       "       [ 6938, 11112]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# True positive | False positive\n",
    "# False negative | True negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df546f-d178-489f-b33e-45e044b50f38",
   "metadata": {},
   "source": [
    "Discuss the output and its impact in the bussiness scenario. Is the cost of a false positive equals to the cost of the false negative? How would you change your algorithm or data in order to maximize the return of the bussiness?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b745824-bd9b-4828-9c25-c83f8a316cb0",
   "metadata": {},
   "source": [
    "We got a model that shows a stable score of approx. 0.61, similar to the downscaling one.\n",
    "The false negative's cost is much more adverse in this situation - these are people who will not be targeted with the fundraising campaign and then are likely not to contribute.\n",
    "Given the mean donation amount of 13 USD, a total of approx. 7k false negatives will translate to a 90k USD loss.\n",
    "On the flip side, directing the false positives (people who will not donate despite targetted campaign) will only cost approx. 0.6 YSD x 7k, or 4.2k USD in total.\n",
    "\n",
    "To minimize the losses, we should aim to reduce the number of false negatives. \n",
    "We should try out different classification models (there are 29), see below, combined with imbalance treatments (incl. SMOTE) to finds out a model that shows the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e2de55-0d44-4462-807d-e8bca5445f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8b4f31-1c24-464c-aaaf-5f2cf84c3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test_regression.reset_index(drop=True, inplace=True)\n",
    "data = pd.DataFrame([])\n",
    "data = pd.concat([X_test,pd.Series(y_pred)], axis = 1)\n",
    "data.columns = [*data.columns[:-1], 'predicted_donor']\n",
    "data = pd.concat([data,y_test_regression], axis = 1)\n",
    "data = data.rename(columns={'TARGET_D': 'actual donation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47a4d3-d17f-4ed6-8897-122061ba8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Lab 2 Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93a7ada-4930-4d75-9809-b88c556400a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data accuracy was:  -0.3489348526815028\n",
      "train data accuracy was:  -0.3566195534503511\n"
     ]
    }
   ],
   "source": [
    "# Building regression model\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regr = DecisionTreeRegressor(max_depth=15)\n",
    "model = regr.fit(X_train, y_train)\n",
    "\n",
    "print(\"test data accuracy was: \",regr.score(X_test, y_test_regression))\n",
    "print(\"train data accuracy was: \",regr.score(X_train, y_train_regression))\n",
    "\n",
    "#-0.36.. interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc246a9-c508-4807-8ce1-4636e9089b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat with RFE first\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "y = y_train_regression\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()\n",
    "rfe = RFE(lm, n_features_to_select=20, verbose=False)\n",
    "rfe.fit(X_train_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb80352-21b1-4c0f-8f8c-ec4eeb063188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = rfe.ranking_, columns=['Rank'])\n",
    "df['Column_name'] = pd.DataFrame(X_train).columns\n",
    "df[df['Rank']==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
